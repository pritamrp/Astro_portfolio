---
layout: ../../layouts/post.astro
title: Data Quality in pre training LLM
description: Precision Beats Power...!
dateFormatted: June , 2024
---


Few days back, we saw the introduction of two new LLMs: Meta's Llama and Microsoft's Phi-3 model. Interestingly, they have one thing in common. They both are trained on high-quality data, allowing them to achieve remarkable results with fewer tokens.

The reason for achievement is far simple than expected. While Previous LLMs were trained on massive amounts of internet data, which can be a bit chaotic.

When these large models are trained, they encounter a variety of data, some of which may contradict each other, leading to a loss of context. As a result, the model struggles to distinguish what's important and ends up absorbing patterns indiscriminately.

However, using high-quality data changes the game. The model not only grasps context better but also incorporates it in a way that makes sense, leading to better outcomes.

While many were eager to find practical uses for LLMs without getting lost in hallucination, it seems the key lies in something quite simple: Data Quality.


## LinkedIn

https://www.linkedin.com/posts/pritampandit_precision-beats-power-few-days-back-activity-7190885091332554752-xwgM?utm_source=share&utm_medium=member_desktop

